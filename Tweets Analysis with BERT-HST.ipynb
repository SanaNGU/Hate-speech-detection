{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Analysis with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to read the csv file as a tadtfram, and att header to your data\n",
    "testset = pd.read_csv(\"hasoc2019_en_test-2919.tsv\",sep='\\t')\n",
    "trainset = pd.read_csv(\"english_dataset.tsv\",sep=\"\\t\")\n",
    "#set id as index --- this helps in moving  arround the dataframe \n",
    "testset.set_index('id',inplace=True)\n",
    "trainset.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hasoc_en_1</th>\n",
       "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasoc_en_2</th>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasoc_en_3</th>\n",
       "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasoc_en_4</th>\n",
       "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasoc_en_5</th>\n",
       "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        tweet task_1 task_2  \\\n",
       "id                                                                            \n",
       "hasoc_en_1  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   NONE   \n",
       "hasoc_en_2  @politico No. We should remember very clearly ...    HOF   HATE   \n",
       "hasoc_en_3  @cricketworldcup Guess who would be the winner...    NOT   NONE   \n",
       "hasoc_en_4  Corbyn is too politically intellectual for #Bo...    NOT   NONE   \n",
       "hasoc_en_5  All the best to #TeamIndia for another swimmin...    NOT   NONE   \n",
       "\n",
       "           task_3  \n",
       "id                 \n",
       "hasoc_en_1   NONE  \n",
       "hasoc_en_2    TIN  \n",
       "hasoc_en_3   NONE  \n",
       "hasoc_en_4   NONE  \n",
       "hasoc_en_5   NONE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the first five row of your data\n",
    "trainset.head()\n",
    "#you can notice now the id is bold which means it is an index  not data any more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data pre preocessing \n",
    "- check data balance\n",
    "- remove unuseful data(nocode,not-relevent)\n",
    "- convert category to integer label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT    4456\n",
       "HOF    2549\n",
       "Name: task_1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data balance\n",
    "#count howmany time each uniqe instance in our data\n",
    "total=[trainset,testset]\n",
    "#Ignoring indexes on the concatenation axisÂ¶\n",
    "total_data=pd.concat(total, ignore_index=True, sort=False)\n",
    "total_data.task_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "sns.countplot(total_data.task_1)\n",
    "pyplot.xlabel('category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## you can see now we have class imbalance and we need to deal with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOT' 'HOF']\n",
      "{'NOT': 0, 'HOF': 1}\n"
     ]
    }
   ],
   "source": [
    "#get  unique labels from category\n",
    "labels = total_data.task_1.unique()#  you can use labels = set(df['category']) \n",
    "print(labels)# {sad', 'disgust', 'surprise', 'not-relevant', 'happy', 'angry'}\n",
    "\n",
    "#Build  a dictionary  to map emotions to integer\n",
    "#emo2int={'happy':'0','not-relevant':'1','angry':'2','surprise ':'3','sad':'4'}\n",
    "#more automated  way to that \n",
    "emo2int = {}\n",
    "for index, label in enumerate(labels):#enumerate() takes iterator (set,list,dic,..etc)and returns tuple of index and the value \n",
    "    emo2int[label] = index \n",
    "print(emo2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet task_1 task_2 task_3  \\\n",
       "0  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   NONE   NONE   \n",
       "1  @politico No. We should remember very clearly ...    HOF   HATE    TIN   \n",
       "2  @cricketworldcup Guess who would be the winner...    NOT   NONE   NONE   \n",
       "3  Corbyn is too politically intellectual for #Bo...    NOT   NONE   NONE   \n",
       "4  All the best to #TeamIndia for another swimmin...    NOT   NONE   NONE   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace \n",
    "#dataframe.replace() function is used to replace a string, regex, list, dictionary, series, number etc. from a dataframe\n",
    "total_data['label'] = total_data.task_1.replace(emo2int)\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalance  and train/test split\n",
    "### we will split each class to make sure all classes appear in the train/val/test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3787, 1: 2167})\n",
      "Counter({0: 669, 1: 382})\n"
     ]
    }
   ],
   "source": [
    "#we splite the text and labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(total_data['tweet'], total_data['label'], test_size=0.15, random_state=0, stratify=total_data['label'])#we use stratify to make sure we splite according to all classes\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5954\n",
      "Counter({0: 3787, 1: 2167})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'train labels')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##we can also split according to the index \n",
    "X_train, X_val, y_train, y_val = train_test_split( total_data.index.values, total_data['label'],test_size = 0.15,random_state=17,stratify=total_data['label'])\n",
    "print(len(y_train))\n",
    "print(Counter(y_train))\n",
    "\n",
    "sns.barplot(list(Counter(y_train).keys()), list(Counter(y_train).values()))\n",
    "pyplot.xlabel('train labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 669, 1: 382})\n",
      "1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'test labels')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Counter(y_test))\n",
    "print(len(y_test))\n",
    "sns.barplot(list(Counter(y_test).keys()), list(Counter(y_test).values()))\n",
    "pyplot.xlabel('test labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>1</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet task_1 task_2 task_3  \\\n",
       "0  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   NONE   NONE   \n",
       "1  @politico No. We should remember very clearly ...    HOF   HATE    TIN   \n",
       "2  @cricketworldcup Guess who would be the winner...    NOT   NONE   NONE   \n",
       "3  Corbyn is too politically intellectual for #Bo...    NOT   NONE   NONE   \n",
       "4  All the best to #TeamIndia for another swimmin...    NOT   NONE   NONE   \n",
       "\n",
       "   label data_type  \n",
       "0      0   not_set  \n",
       "1      1   not_set  \n",
       "2      0   not_set  \n",
       "3      0   not_set  \n",
       "4      0   not_set  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['data_type'] = ['not_set']*total_data.shape[0]\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DhoniKeepsTheGlove | WATCH: Sports Minister K...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@politico No. We should remember very clearly ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@cricketworldcup Guess who would be the winner...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corbyn is too politically intellectual for #Bo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the best to #TeamIndia for another swimmin...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet task_1 task_2 task_3  \\\n",
       "0  #DhoniKeepsTheGlove | WATCH: Sports Minister K...    NOT   NONE   NONE   \n",
       "1  @politico No. We should remember very clearly ...    HOF   HATE    TIN   \n",
       "2  @cricketworldcup Guess who would be the winner...    NOT   NONE   NONE   \n",
       "3  Corbyn is too politically intellectual for #Bo...    NOT   NONE   NONE   \n",
       "4  All the best to #TeamIndia for another swimmin...    NOT   NONE   NONE   \n",
       "\n",
       "   label data_type  \n",
       "0      0     train  \n",
       "1      1     train  \n",
       "2      0       val  \n",
       "3      0     train  \n",
       "4      0     train  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.loc[X_train, 'data_type'] = 'train'\n",
    "total_data.loc[X_val, 'data_type'] = 'val'\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Loading Tokenizer and Encoding our Data\n",
    " - now we want to tokenize the tweets(text) which mean splits the sentence into words \n",
    " - after tokenization we will encode the words(convert them into integer number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bert model can do all these tasks mentioned  above\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#both  encoded_data will return dictionary \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    total_data[total_data.data_type == 'train'].tweet.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    total_data[total_data.data_type == 'val'].tweet.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=256,\n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(total_data[total_data.data_type == 'train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(total_data[total_data.data_type == 'val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5954"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup Bert-pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', \n",
    "    num_labels = len(emo2int),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what we did above, we already knew  that BERT essentially takes in text and is able to encode it in a meaningful way based on this huge corpus of data that it was initially trainedon.We want to use this pre-trained model and fine tuning it by  adding and layer on top of it of size 6(number of our classes) because we've got six difference classes that we want to be able to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data with Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 4#32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler = RandomSampler(dataset_train),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler = RandomSampler(dataset_val),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Optimizer and Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5,# 2e-5 ... 5e-5 \n",
    "                  eps=1e-8)\n",
    "epochs = 5\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis = 1). flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    labels_dict_inverse = {v: k for k, v in emo2int.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis = 1). flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {labels_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])/len(y_true)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The seed() method is used to initialize the random number generator.\n",
    "#A random seed specifies the start point when a computer generates a random number sequence.\n",
    "#When you ask for random number in pytorch (with torch.rand() or t.uniform_() for example) these random numbers are generated from a specific algorithm.\n",
    "#A nice property of this algorithm is that you can fix itâs starting point and it will always generate the same random numbers afterwards. That way, you can have reproducible code even with random functions in it.\n",
    "#The seed is just this starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85de82108c8947b6b12ef6334daa7cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.6115661630991164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ef268e6cda4f0e81c70fa9e1567574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.572626022678433\n",
      "F1 Score (weighted): 0.6944581690162114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.5250233539534623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a823e900ea24371b023567462b169a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6891982302521215\n",
      "F1 Score (weighted): 0.6988823708548755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.49356744949667747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bd546745864f7cab505af6faa35d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.0507998177499482\n",
      "F1 Score (weighted): 0.7149033439915145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.391101350999219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5255b92a15b34341a8e1adafba499b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.2964454672553323\n",
      "F1 Score (weighted): 0.6986168871366724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1489 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.2920576767255399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cb6382d5d64a079767e93f82e90305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 1.4790584607557817\n",
      "F1 Score (weighted): 0.6971876902940234\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc='Epoch {:1d}'.format(epoch),\n",
    "                       leave=False,\n",
    "                       disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "        \n",
    "    torch.save(model.state_dict(), f'./BERT2_ft_epoch{epoch}.model')\n",
    "    \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load('BERT2_ft_epoch2.model', \n",
    "               map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be28809255bf444a97dc4d0bb2639be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: NOT\n",
      "Accuracy: 0.8639760837070254\n",
      "Class: HOF\n",
      "Accuracy: 0.450261780104712\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
